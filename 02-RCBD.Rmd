---
output:
  pdf_document: default
  html_document: default
---
# Randomised Complete Block Design (RCBD) {#rcbd}

*Aim* Conduct a standard set of analyses from an RCBD trial in R

*Assumptions* you know some basic R, have R and RStudio already installed on your computer and you are familiar with the standard analyses of field trials.

Section 1 provides the steps used to produce the analysis, with no further explanation.  

Section 2 provides some commentary and explanation on how each of these commands work, what output is created, and why these commands were chosen.     
Section 3 deals with certain key aspects of the statistical methodology. 

## About the data

The data used in this example is from a study was conducted in Eastern Zambia and the main aim was to improve on the efficiency of the natural fallows by using appropriate trees that may have relevance in soil fertility regeneration within permissible fallow periods.

The design was a RCBD experiment with 4 blocks and 9 treatments. If you open the file with Excel, you will see that the first row contains the names of the variables and each of the 36 subsequent rows provides the measurement of the yield (the column "yield" within the data) of a plot (the column "plot"), within a block (the column "rep"), after a specific treatment (the column "treat"). 

```{r,echo=FALSE}
fallow <- read.csv("Data/Fallow N2.csv")
```


```{r,echo=FALSE}
DT::datatable(fallow)
```


Our objective here is to study the impact of the treatment factor (9 different types of fallow) on the crop yields of maize.

The following steps were followed to generate the output in this document.
The data was organized in excel rectangle columns with the different variables appearing in excel columns. All data checks were done in excel, meaningful data was selected and a copy of this data file was stored as a CSV file to make data import easy in R.   

The data file used in this analysis can be downloaded  [here](https://raw.githubusercontent.com/sdumble1/RAgExperiments/master/Data/Fallow%20N2.csv). 
You can download a script file containing all of these commands [here] (https://raw.githubusercontent.com/sdumble1/RAgExperiments/master/R/RCBD.r). You can download a standalone pdf file containing this tutorial [here](https://raw.githubusercontent.com/sdumble1/RAgExperiments/master/PDF/RCBD.pdf). 

## Steps in analysis using R


1. Install R packages needed
```{r, eval=FALSE}
library(ggplot2)
library(doBy)
library(lmerTest)
library(lattice)
library(emmeans)
library(multcompView)

```
2. Import data
```{r, eval=FALSE}
fallow <- read.csv("C:/Users/Admin/Desktop/Fallow N2.csv")
```
3. Check and update data
```{r,eval=FALSE}
summary(fallow)
str(fallow)
fallow$rep<-factor(fallow$rep)
fallow$plot<-factor(fallow$plot)
```
4. Explore data
```{r, eval=FALSE}
ggplot(data=fallow,aes(y=yield,x=treat,col=rep))+geom_point()
summaryBy(yield~treat, data=fallow, FUN=c(min,max,mean,median,sd))
```

5. Specify a model for data
```{r, eval=FALSE}
rcbdmodel1<-lmer(yield~treat+(1|rep),data=fallow)
```

6. Check the model
```{r,eval=FALSE}
plot(rcbdmodel1)

qqmath(rcbdmodel1)

```
7. Interpret the model
```{r, eval=FALSE}
anova(rcbdmodel1,ddf="Kenward-Roger")
print(VarCorr(rcbdmodel1), comp=("Variance"))
ranova(rcbdmodel1)
```

8. Present the results from the model
```{r, eval=FALSE}
emmip(rcbdmodel1,~treat,CIs = TRUE)
emmeans(rcbdmodel1, ~treat)
cld(emmeans(rcbdmodel1, ~treat))
```

## Explanation of Steps
### Install R packages needed 

In this step, the code serves as the installation and loading of the five packages used during data exploration and analysis. One of the key advantages of using R over the many alternatives is the quality and scope available in the additional packages, so make sure you familiarise yourself with how to install and load packages. For a general introduction explaining what R packages are and how they work, there is a really useful guide on datacamp: https://www.datacamp.com/community/tutorials/r-packages-guide. For each of these packages to be installed, using `install.packages("name of package")`. This requires a reliable internet connection and a correctly installed and configured version of R and RStudio. If you are having difficulties installing these packages then resources are available to assist, https://www.dummies.com/programming/r/how-to-install-and-configure-rstudio/, or please ask for help.


```{r,eval=FALSE}
install.packages("ggplot2")
library(ggplot2)
```
`ggplot2` This package provides a powerful graphics language for creating elegant and complex graphs in R.
Functions used from this package in this tutorial are: `ggplot()`,`geom_point()`

```{r,eval=FALSE}
install.packages("doBy")
library(doBy)
```
`doBy` Allows easy production of summary statistic tables
Functions used from this package in this tutorial are: `summaryBy()`

```{r,eval=FALSE}
install.packages("lmerTest")
library(lmerTest)
```
`lmerTest` Allows produce of flexible mixed effects regression models, similar to REML in Genstat.
Functions used from this package in this tutorial are: `lmer()`,`ranova()`,`VarCorr()`,

```{r,eval=FALSE}
install.packages("lattice")
library(lattice)
```
```lattice``` contains functions for producing residual plots for mixed models
Functions used from this package in this tutorial are: `qqmath()`

```{r,eval=FALSE}
install.packages("emmeans")
library(emmeans)
```
`emmeans` Estimated marginal means (also known as least squares means) helps provide expected mean values and confidence intervals from statistical models.
Functions used from this package in this tutorial are: `emmeans()`,`emmip()`

```{r,eval=FALSE}
install.packages("multcompView")
library(multcompView)
```
`multcompView` allows for mean seperation methods on analyses
Functions used from this package in this tutorial are: `CLD()`

```{r,include=FALSE,echo=FALSE}
library(ggplot2)
library(emmeans)
library(doBy)
library(lmerTest)
library(multcompView)
library(lattice)
```

### Import data

Our data set saved as a CSV file, so we can use the read.csv commmand to import the data. We are going to assign the name of the data with R to be ```fallow```. Note that in R Studio you could also use the "Import Dataset" menu to import a dataset, if you don't want to type out the full file name. 

```{r,eval=FALSE}
fallow <- read.csv("C:/Users/Admin/Desktop/Fallow N2.csv")
```

In this line I am telling R to read in the dataset Fallow N2.csv; which is saved in my computer in the folder C:/Users/Admin/Desktop . It is very unlikely that this line will work for you, unless you happen to have saved the dataset into exactly the same location, so you will need to update this line with the location from your own machine.


###	Check and update data

When reading data into R it is always useful to check that data is in the format expected. 

```{r,echo=FALSE}
DT::datatable(fallow)
```


How many variables are there? How many rows? How have the columns been read in? The `summary()` command can help to show if the data is being treated correctly.

```{r}
summary(fallow)
```

Where data is being treated as a numeric variable (i.e. a number) ```summary``` provides statistics like the mean, min and max. Where data is being treated like a categorical variable (i.e. a group) then `summary()` provides frequency tables.


From the results we can see that the variables rep and plot are being considered as numeric variables. However these are grouping variables, not number variables, the numbers used are simply codes. If we do not rectify this then our analysis later will be incorrect and meaningless.  
This can also be seen more explicitly using the `str()` function.

```{r}
str(fallow)
```

So we need to convert these variables into factors. 

```{r}
fallow$rep<-factor(fallow$rep)
fallow$plot<-factor(fallow$plot)
```

These commands take the columns rep and plot within the data frame fallow, converts into factors and saves the result in a columns called rep and plot within fallow, i.e. this overwrites the existing columns. When making column transformations it can sometimes be a good idea to be more cautious and check that the output is expected before making changes to the columns from the original data.

### Explore data

#### Plots

With this code we want to summarize data fallow by yield as the response and treatment as a factor using points.

```{r}
ggplot(data=fallow,aes(y=yield,x=treat))+
  geom_point()
```
We could also extend this to identify which points came from which reps.

```{r}
ggplot(data=fallow,aes(y=yield,x=treat,col=rep))+
  geom_point()
```

Using ggplot2 we can easily change between different types of graph with small changes to the code. Boxplots are very useful if we have lots of data in each group, but in this example we only have 4 points so it is easy to visualise all of our data using a scatter plot. But the only change we would need to make to our original code is to change geom_point() to geom_boxplot().

```{r}
ggplot(data=fallow,aes(y=yield,x=treat))+
    geom_boxplot()
```

From the figures produced we can see that treatment 1 has consistently high yields. The lowest yield recorded for treatment 1 is higher than the highest yield recorded for any of the other treatments. Treatments 5 and 8 had consistently low yields.

#### Summary Statistics

To produce summary statistics, by group, there are many options within R. One option is to use the summaryBy function, from the doBy library. The code used for this is quite similar to the code we will use to produce models in a later step.

```{r}
summaryBy(yield~treat, data=fallow, FUN=mean)
```

We can also calculate multiple statistics in the same line of code.

```{r}
summaryBy(yield~treat, data=fallow, FUN=c(min,max,mean,median,sd))
```


### Specify a model for data


In this design, an RCBD, we have one treatment factor, "treat", and one layout factor "rep". More information about model fitting can be found in section 2.

```{r}
rcbdmodel1<-lmer(yield~treat+(1|rep),data=fallow)
```


R is unlike many other software packages in how it fits models. The best way of handling models in R is to assign the model to a name (in this case rcbdmodel1) and then ask R to provide different sorts of output for this model. When you run the above line you will get now output from the data - this is what we expected to see!

### Check the model

Before interpretting the model any further we should investigate the model validity, to ensure any conclusions we draw are valid. There are 3 assumptions that we can check for using standard model checking plots.
1. Homogeneity (equal variance)  
2. Values with high leverage  
3. Normality of residuals  

The function plot() when used with a model will plot the fitted values from the model against the expected values.


```{r}
plot(rcbdmodel1)
```
The residual Vs fitted plot is a scatter plot of the Residuals on the y-axis and the fitted on the x-axis and the aim for this plot is to test the assumption of equal variance of the residuals across the range of fitted values. Since the residuals do not funnel out (to form triangular/diamond shape) the assumption of equal variance is met. 

We can also see that there are no extreme values in the residuals which might be potentially causing problems with the validity of our conclusions (leverage)

To assess the assumption of normality we can produce a qqplot. This shows us how closely the residuals follow a normal distribution - if there are severe and syste,matic deviations from the line then we may want to consider an alternative distribution.

```{r}
qqmath(rcbdmodel1)
```
In this case the residuals seem to fit the assumption required for normality.

### Interpret Model

The anova() function only prints the rows of analysis of variance table for treatment effects when looking at a mixed model fitted using lmer().

```{r}
anova(rcbdmodel1,ddf="Kenward-Roger")
```

ddf=Kenward-Roger tells R which method to use for determining the calculations of the table; this option matches the defaults found within SAS or Genstat. The ANOVA table suggests a highly significant effect of the treatment on the yield.

To obtain the residual variance, and the variance attributed to the blocks we need an additional command. From these number it is possible to reconstruct a more classic ANOVA table, if so desired.
```{r}
print(VarCorr(rcbdmodel1), comp=("Variance"))
```

```{r}
ranova(rcbdmodel1)
```



### Present the results from the model

To help understand what the significant result from the ANOVA table means we can produce several plots and tables to help us. First we can use the function emmip() to produce plots of the modelled results, including 95% confidence intervals.

```{r}
emmip(rcbdmodel1,~treat,CIs = TRUE)
```


To obtain the numbers used in creating this graph we can use the function emmeans.
```{r}
emmeans(rcbdmodel1, ~treat)
```

And one method for conducting mean separation analysis we can use the function cld().

```{r}
CLD(emmeans(rcbdmodel1, ~treat))
```

In the output, groups sharing a letter in the .group are not statistically different from each other.


## Methodological Principles

There are always many different ways of doing all that we have done here in R. The less complex the method/code is, the better it is for you so that you can easily grasp the method.

For instance, we have fitted our model as a linear mixed effect model rather than traditional ANOVA because lmer model has the following advantages: 

1.	They are very flexible especially where we have repeated measures, for instance you don’t need to have the same number of observations per subject/treatment.
2.	Ability to account for a series of random effects. Not only are farms/farmers/plots…. different from each other, but things with in farms/plots….. also differ . Not taking these sources of variation into account will lead to underestimations of accuracy.
3.	Allows for generalization of non-normal data.  
4.	Handling missing data: If the percentage of missing data is small and that data missing is a random sample of the data set,data from the observations with missing data can be analysed with lmer (unlike other packages that would do listwise deletion.
5.	Takes into account variation that is explained by the predictor variables of interest ie fixed effects and variation that is not explained by these predictors ie random effects.
